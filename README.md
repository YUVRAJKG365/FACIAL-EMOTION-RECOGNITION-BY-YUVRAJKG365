# ğŸ­ FACIAL-EMOTION-RECOGNITION-YKG

## ğŸš€ AI-Powered Facial Emotion Recognition System  
An advanced Deep Learning solution for **real-time facial emotion detection**, built with **CNN & TensorFlow**, featuring an intuitive **Tkinter GUI** for seamless user interaction.

---

ğŸ“Œ **Developed by Yuvraj Kumar Gond** during his **AI/ML Internship at ShadowFox Company**, a multinational firm based in **Bengaluru & Sydney**.

> ğŸ—‚ï¸ `t1.py` â€“ Main Application Code  
> ğŸ§  `t11.py` â€“ Model Training & Deep Learning Scripts  

---

## ğŸ“Œ About the Project

The **Facial Emotion Recognition System** is designed to accurately detect and classify human emotions using state-of-the-art **deep learning**. It utilizes **Convolutional Neural Networks (CNN)** trained on the **FER 2013 dataset**, allowing recognition from both static images and real-time webcam feeds.

### ğŸ”¥ Unique Features

- ğŸ§  **Self-Learning Capability** â€“ Continuously improves with new training data  
- ğŸ–¥ï¸ **GUI Interface** â€“ Clean, interactive, and built using Tkinter  
- ğŸ¥ **Real-Time Detection** â€“ Optimized for webcam-based emotion capture  
- âš™ï¸ **Automated Preprocessing** â€“ Uses image augmentation & grayscale conversion  
- ğŸ›¡ï¸ **Overfitting Prevention** â€“ Includes Dropout, EarlyStopping, and ModelCheckpoint  
- ğŸ“Š **High Accuracy & Speed** â€“ Built for scalable and fast real-time classification  

---

## ğŸ¯ Potential Use Cases

âœ… Emotion tracking in **AI assistants** & **chatbots**  
âœ… **Mental health monitoring** through facial analytics  
âœ… **Sentiment analysis** in customer experience tools  
âœ… **Interactive gaming & VR** based on real-time emotions  
âœ… AI-driven **learning platforms** or classroom mood detectors  

---

## ğŸ”¬ How the Model Works

### 1ï¸âƒ£ Image Preprocessing  
- Resizing and grayscale conversion  
- Image augmentation (flip, zoom, rotation, brightness)  
- Normalization for deep learning input  

### 2ï¸âƒ£ Model Training  
- Built with **Convolutional Neural Networks (CNN)**  
- Layers: Conv2D â†’ MaxPooling â†’ Flatten â†’ Dense â†’ Dropout  
- Optimizer: **Adam**  
- Loss Function: **Categorical Crossentropy**  
- Metrics: Accuracy, Precision, Recall  

### 3ï¸âƒ£ Emotion Classification  
- Final layer uses **Softmax** for multi-class output  
- Emotions classified include:  
  ğŸ˜ƒ Happyâ€ƒğŸ˜¢ Sadâ€ƒğŸ˜  Angryâ€ƒğŸ˜ Neutralâ€ƒğŸ˜² Surpriseâ€ƒğŸ¤¢ Disgustâ€ƒğŸ˜¨ Fear  

### 4ï¸âƒ£ Continuous Learning  
- Supports **incremental training** with new labeled data  
- Just drop images into folders and retrain  

---

## ğŸ›  Tech Stack & Tools Used

| Component              | Tool/Library                  |
|------------------------|-------------------------------|
| Programming Language   | Python ğŸ                     |
| Deep Learning Framework| TensorFlow & Keras âš¡         |
| Dataset                | FER 2013 (Kaggle) ğŸ“Š          |
| Image Preprocessing    | OpenCV, NumPy ğŸ“·              |
| Model Architecture     | CNN (Convolutional Neural Network) |
| GUI Interface          | Tkinter ğŸ¨                   |
| Performance Metrics    | Classification Report, Confusion Matrix ğŸ“ˆ |
| Model Format           | `.keras` for model storage   |

---

## ğŸ¨ GUI & ML Design Concept

### ğŸ”¹ Graphical User Interface (GUI)
- Built with **Tkinter** for a clean, interactive look  
- Allows:
  - ğŸ“· Image Upload
  - ğŸ¥ Webcam Capture
  - ğŸ§  Emotion Prediction Display
  - ğŸ“š Option to Retrain with New Images

### ğŸ”¹ Machine Learning Architecture
- Uses deep **CNN** with:
  - Conv2D, MaxPooling2D, Dropout, Flatten, Dense  
  - Final Softmax for emotion classification  
- Trained with:
  - ğŸ“Š 80% Training, 20% Validation  
  - ğŸ” Batch Size: 32  
  - â±ï¸ Epochs: 50 (with EarlyStopping)

---

## ğŸ“Š Model Performance & Evaluation

âœ… **Test Accuracy:** ğŸš€ _Insert Final Test Accuracy Here_  
âœ… **Validation Loss:** ğŸ“‰ _Insert Final Loss Value Here_  

### Evaluation Metrics:
- ğŸ“‹ **Classification Report** â€“ Precision, Recall, F1-Score  
- ğŸ”„ **Confusion Matrix** â€“ Visual emotion prediction accuracy  

---

## ğŸš€ How to Use the Model

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/your-github-username/Facial-Emotion-Recognition.git
cd Facial-Emotion-Recognition
2ï¸âƒ£ Install Dependencies
bash
Copy
Edit
pip install tensorflow numpy opencv-python scikit-learn matplotlib pillow
3ï¸âƒ£ Run the Model for Emotion Detection
bash
Copy
Edit
python emotion_detection.py
4ï¸âƒ£ Train the Model with New Data (Optional)
Add new images to the train/ directory

Then run:

bash
Copy
Edit
python train_model.py
5ï¸âƒ£ Launch the GUI for Emotion Detection
bash
Copy
Edit
python gui_emotion_recognition.py
ğŸ¤ Acknowledgment
ğŸ’¡ Concept & Development: Yuvraj Kumar Gond
ğŸ¤– AI/ML Support: ChatGPT
ğŸ“‚ Dataset Used: FER 2013 from Kaggle
ğŸ‘¨â€ğŸ« Internship Mentor: (Insert Mentorâ€™s Name)
ğŸ¢ Internship Company: ShadowFox Company (Bengaluru & Sydney)

ğŸ“ Connect With Me!
ğŸ’¼ LinkedIn: Yuvraj Kumar Gond

ğŸ“§ Email: yuviig456@gmail.com

â­ If you find this project helpful, donâ€™t forget to star the repo on GitHub!
